{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601fb41e",
   "metadata": {
    "id": "601fb41e"
   },
   "source": [
    "# MACHINE LEARNING — ASSIGNMENT 2\n",
    "\n",
    "**Topic:** Multi-model classification + Streamlit deployment  \n",
    "**Planned Dataset:** Credit Card Default (UCI/Kaggle)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd1fd4",
   "metadata": {
    "id": "92dd1fd4"
   },
   "source": [
    "## STUDENT INFORMATION\n",
    "\n",
    "\n",
    "- **Name:** HARISH BHATT  \n",
    "- **StudentID:** 2025AA05578@wilp.bits-pilani.ac.in\n",
    "- **Program:** M.Tech (AIML/DSE)  \n",
    "- **Course:** Machine Learning  \n",
    "- **Assignment:** 2  \n",
    "- **Submission Date:** 15-Feb-2026  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028d643",
   "metadata": {
    "id": "b028d643"
   },
   "source": [
    "## 1) Imports & Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f50dfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98f50dfc",
    "outputId": "e730ac70-ca43-45ed-a19b-51c25a728416"
   },
   "outputs": [],
   "source": [
    "# If running in Colab, uncomment and install dependencies as needed\n",
    "!pip -q install pandas numpy scikit-learn xgboost matplotlib seaborn joblib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score,\n",
    "    precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"pandas:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8cbb04",
   "metadata": {
    "id": "de8cbb04"
   },
   "source": [
    "## 2) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vDIEpTq3Xzm3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDIEpTq3Xzm3",
    "outputId": "d570a898-904a-44cd-a998-e024c172051c"
   },
   "outputs": [],
   "source": [
    "# Load pre-split training and testing datasets directly from GitHub\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/Harishbhatt07/ML-Assignment-2/main/model/data/train.csv\"\n",
    "test_url = \"https://raw.githubusercontent.com/Harishbhatt07/ML-Assignment-2/main/model/data/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_url)\n",
    "test_df = pd.read_csv(test_url)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "TARGET_COL = \"default.payment.next.month\"\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET_COL])\n",
    "y_train = train_df[TARGET_COL]\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET_COL])\n",
    "y_test = test_df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca779f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84ca779f",
    "outputId": "8e41b347-730f-40a8-f278-876d136047b1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sanity checks (REQUIRED)\n",
    "MIN_ROWS = 500\n",
    "MIN_FEATURES = 12\n",
    "\n",
    "print(\"Columns:\", len(train_df.columns))\n",
    "print(\"Rows   :\", len(train_df))\n",
    "\n",
    "# Basic shape checks per assignment requirement\n",
    "assert len(train_df) >= MIN_ROWS, f\"Dataset has {len(train_df)} rows; need at least {MIN_ROWS}.\"\n",
    "# features check will be done after defining X (excluding target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385474e",
   "metadata": {
    "id": "3385474e"
   },
   "source": [
    "## 3) Quick EDA / Data Checks (Optional but useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa5054",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f5aa5054",
    "outputId": "da9b0a50-0333-4924-cb3d-c24378807100"
   },
   "outputs": [],
   "source": [
    "# Basic info\n",
    "display(train_df.describe(include='all').T.head(30))\n",
    "print(\"\\nMissing values per column (top 20):\")\n",
    "display(train_df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# Class balance (update target column name if needed)\n",
    "TARGET_COL = \"default.payment.next.month\"\n",
    "if TARGET_COL in train_df.columns:\n",
    "    display(train_df[TARGET_COL].value_counts(dropna=False))\n",
    "else:\n",
    "    print(f\"Target column '{TARGET_COL}' not found. Columns are:\", list(train_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e07ff",
   "metadata": {
    "id": "e83e07ff"
   },
   "source": [
    "## 4) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9cb73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71f9cb73",
    "outputId": "2db92c66-bd2b-49ef-d40b-d67262f7eccb"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Preprocessing for Train/Test\n",
    "# -----------------------------\n",
    "\n",
    "TARGET_COL = \"default.payment.next.month\"  # confirm exact column name\n",
    "\n",
    "# 4.1 Drop ID column if present (Train)\n",
    "if \"ID\" in train_df.columns:\n",
    "    train_df = train_df.drop(columns=[\"ID\"])\n",
    "\n",
    "# 4.2 Drop ID column if present (Test)\n",
    "if \"ID\" in test_df.columns:\n",
    "    test_df = test_df.drop(columns=[\"ID\"])\n",
    "\n",
    "# 4.3 Define X and y separately\n",
    "X_train = train_df.drop(columns=[TARGET_COL])\n",
    "y_train = train_df[TARGET_COL]\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET_COL])\n",
    "y_test = test_df[TARGET_COL]\n",
    "\n",
    "print(\"Train X shape:\", X_train.shape)\n",
    "print(\"Test X shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f68499",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "37f68499",
    "outputId": "8ef15980-de78-43ff-e27e-6f8148b70821"
   },
   "outputs": [],
   "source": [
    "# Feature/target sanity checks (REQUIRED)\n",
    "\n",
    "MIN_FEATURES = 12\n",
    "\n",
    "# 1) Check target exists in both train and test\n",
    "assert TARGET_COL in train_df.columns, f\"Target column not found in train_df: {TARGET_COL}\"\n",
    "assert TARGET_COL in test_df.columns, f\"Target column not found in test_df: {TARGET_COL}\"\n",
    "\n",
    "# 2) Check feature count (on train)\n",
    "n_features = X_train.shape[1]\n",
    "print(\"Number of features (X_train):\", n_features)\n",
    "assert n_features >= MIN_FEATURES, f\"Dataset has {n_features} features; need at least {MIN_FEATURES}.\"\n",
    "\n",
    "# 3) Check train/test have same feature columns (to avoid Streamlit + model issues)\n",
    "assert list(X_train.columns) == list(X_test.columns), \"Train and test feature columns do not match!\"\n",
    "\n",
    "# 4) Target distribution (useful for observations)\n",
    "print(\"\\nTrain target distribution:\")\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest target distribution:\")\n",
    "display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3faf02",
   "metadata": {
    "id": "5d3faf02"
   },
   "source": [
    "## 5) Scaling (for Logistic Regression + KNN; optional for others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008b2b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a008b2b8",
    "outputId": "34b9f6d5-11f9-406f-9470-7119cf81af70"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaled shapes:\", X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80ccc6",
   "metadata": {
    "id": "5e80ccc6"
   },
   "source": [
    "## 6) Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c64d6",
   "metadata": {
    "id": "039c64d6"
   },
   "outputs": [],
   "source": [
    "def get_binary_proba(model, X):\n",
    "    \"\"\"Return P(class=1) for binary classifiers.\"\"\"\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(X)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        # Convert decision scores to pseudo-probabilities via min-max scaling as fallback\n",
    "        scores = model.decision_function(X)\n",
    "        proba = (scores - scores.min()) / (scores.max() - scores.min() + 1e-12)\n",
    "    else:\n",
    "        raise ValueError(\"Model has neither predict_proba nor decision_function.\")\n",
    "    return proba\n",
    "\n",
    "\n",
    "def evaluate_model(model, Xtr, Xte, ytr, yte, label_name=None):\n",
    "    \"\"\"Fit, predict, compute required metrics for binary classification.\"\"\"\n",
    "    model.fit(Xtr, ytr)\n",
    "    y_pred = model.predict(Xte)\n",
    "    y_prob = get_binary_proba(model, Xte)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(yte, y_pred),\n",
    "        \"AUC\": roc_auc_score(yte, y_prob),\n",
    "        \"Precision\": precision_score(yte, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(yte, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(yte, y_pred, zero_division=0),\n",
    "        \"MCC\": matthews_corrcoef(yte, y_pred),\n",
    "    }\n",
    "\n",
    "    # Confusion matrix + report\n",
    "    cm = confusion_matrix(yte, y_pred)\n",
    "    report = classification_report(yte, y_pred, digits=4, zero_division=0)\n",
    "\n",
    "    return metrics, cm, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117af63",
   "metadata": {
    "id": "3117af63"
   },
   "source": [
    "## 7) Train the 6 Required Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f2946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "0b1f2946",
    "outputId": "5a493540-4711-4c3f-81b5-61638940a9a2"
   },
   "outputs": [],
   "source": [
    "  # =========================\n",
    "# Train + Evaluate 6 Models\n",
    "# =========================\n",
    "\n",
    "results = []\n",
    "artifacts = {}  # store models + cm/report for later Streamlit use\n",
    "\n",
    "# 1) Logistic Regression (scaled) — optional: class_weight=\"balanced\"\n",
    "lr = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
    "m, cm, report = evaluate_model(lr, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "results.append((\"Logistic Regression\", m))\n",
    "artifacts[\"Logistic Regression\"] = {\"model\": lr, \"cm\": cm, \"report\": report}\n",
    "\n",
    "# 2) Decision Tree (unscaled)\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "m, cm, report = evaluate_model(dt, X_train, X_test, y_train, y_test)\n",
    "results.append((\"Decision Tree\", m))\n",
    "artifacts[\"Decision Tree\"] = {\"model\": dt, \"cm\": cm, \"report\": report}\n",
    "\n",
    "# 3) KNN (scaled)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "m, cm, report = evaluate_model(knn, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "results.append((\"KNN\", m))\n",
    "artifacts[\"KNN\"] = {\"model\": knn, \"cm\": cm, \"report\": report}\n",
    "\n",
    "# 4) Naive Bayes (Gaussian) (scaled)\n",
    "nb = GaussianNB()\n",
    "m, cm, report = evaluate_model(nb, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "results.append((\"Naive Bayes\", m))\n",
    "artifacts[\"Naive Bayes\"] = {\"model\": nb, \"cm\": cm, \"report\": report}\n",
    "\n",
    "# 5) Random Forest (unscaled)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=12,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "m, cm, report = evaluate_model(rf, X_train, X_test, y_train, y_test)\n",
    "results.append((\"Random Forest (Ensemble)\", m))\n",
    "artifacts[\"Random Forest (Ensemble)\"] = {\"model\": rf, \"cm\": cm, \"report\": report}\n",
    "\n",
    "# 6) XGBoost (unscaled)\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "m, cm, report = evaluate_model(xgb, X_train, X_test, y_train, y_test)\n",
    "results.append((\"XGBoost (Ensemble)\", m))\n",
    "artifacts[\"XGBoost (Ensemble)\"] = {\"model\": xgb, \"cm\": cm, \"report\": report}\n",
    "\n",
    "# Comparison table\n",
    "results_df = pd.DataFrame([r[1] for r in results], index=[r[0] for r in results])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a92b1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "13a92b1d",
    "outputId": "bdb0209e-ed19-49cd-fce1-d6e807c934c3"
   },
   "outputs": [],
   "source": [
    "# Results validation (REQUIRED — prevent accidental 0.0 / missing metrics)\n",
    "\n",
    "REQUIRED_MODELS = [\n",
    "    \"Logistic Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"KNN\",\n",
    "    \"Naive Bayes\",\n",
    "    \"Random Forest (Ensemble)\",\n",
    "    \"XGBoost (Ensemble)\"\n",
    "]\n",
    "\n",
    "# Check all required models present\n",
    "missing = [m for m in REQUIRED_MODELS if m not in results_df.index]\n",
    "assert not missing, f\"Missing model results for: {missing}\"\n",
    "\n",
    "# Check for NaNs\n",
    "assert not results_df.isna().any().any(), \"Some metrics are NaN. Check AUC/probabilities.\"\n",
    "\n",
    "# Check metrics not all zeros\n",
    "for col in results_df.columns:\n",
    "    assert (results_df[col] != 0).any(), f\"Column {col} looks all zeros — did metrics compute correctly?\"\n",
    "\n",
    "print(\"✅ Results table contains all required models and valid metric values.\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tGCB5X1K1lDm",
   "metadata": {
    "id": "tGCB5X1K1lDm"
   },
   "source": [
    "## 8) Plots and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XsE1fvDQm-H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "9XsE1fvDQm-H",
    "outputId": "3d504b24-01c6-4fd2-cc41-4153eaafd024"
   },
   "outputs": [],
   "source": [
    "# Bar Plot — Accuracy Comparison\n",
    "plt.figure(figsize=(8,5))\n",
    "results_df[\"Accuracy\"].sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Accuracy Comparison Across Models\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNt93fbUQr_T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "zNt93fbUQr_T",
    "outputId": "a8b63444-8243-43f9-cf1c-dc535b11f305"
   },
   "outputs": [],
   "source": [
    "#Bar Plot — AUC Comparison\n",
    "plt.figure(figsize=(8,5))\n",
    "results_df[\"AUC\"].sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"AUC Score Comparison Across Models\")\n",
    "plt.xlabel(\"AUC Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Vv9HWC_Q2T8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "8Vv9HWC_Q2T8",
    "outputId": "0ffe5e5d-d730-4055-d88f-e80cc25c184a"
   },
   "outputs": [],
   "source": [
    "#Grouped Bar Chart — Precision, Recall, F1 Comparison\n",
    "metrics_to_plot = [\"Precision\", \"Recall\", \"F1\"]\n",
    "\n",
    "results_df[metrics_to_plot].plot(kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Precision, Recall, and F1 Comparison\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lm0ifQbhRBqC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Lm0ifQbhRBqC",
    "outputId": "36c7f7a4-b16b-4705-8e39-a515cd7431ec"
   },
   "outputs": [],
   "source": [
    "# MCC Comparison Plot (Advanced Metric)\n",
    "plt.figure(figsize=(8,5))\n",
    "results_df[\"MCC\"].sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Matthews Correlation Coefficient Comparison\")\n",
    "plt.xlabel(\"MCC Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d43fc",
   "metadata": {
    "id": "0a9d43fc"
   },
   "source": [
    "## 9) Identify the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16285458",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16285458",
    "outputId": "7c5088ac-dd87-4fcb-e992-13595528589f"
   },
   "outputs": [],
   "source": [
    "# You can choose based on AUC, MCC, or F1. Here we pick best by AUC.\n",
    "best_model_name = results_df[\"AUC\"].idxmax()\n",
    "best_model = artifacts[best_model_name][\"model\"]\n",
    "\n",
    "print(\"Best model by AUC:\", best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14786e24",
   "metadata": {
    "id": "14786e24"
   },
   "source": [
    "## 10) Visuals: Confusion Matrix & Report (for all models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5036e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "df5036e4",
    "outputId": "37b9cf74-7872-4534-e58a-c1578c1a1fb8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for model_name, obj in artifacts.items():\n",
    "\n",
    "    cm = obj[\"cm\"]\n",
    "    report = obj[\"report\"]\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(report)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix — {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb52649",
   "metadata": {
    "id": "4bb52649"
   },
   "source": [
    "## 11) Save Artifacts for Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c2d3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b35c2d3e",
    "outputId": "f2cf273c-983c-45b0-d6d9-0089936e786d"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Save Artifacts for Streamlit\n",
    "# =========================\n",
    "import os, joblib\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Save scaler (needed for LR + KNN + Naive Bayes)\n",
    "joblib.dump(scaler, \"model/scaler.pkl\")\n",
    "\n",
    "# Save each model\n",
    "for name, obj in artifacts.items():\n",
    "    safe_name = (\n",
    "        name.lower()\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\"/\", \"_\")\n",
    "    )\n",
    "    joblib.dump(obj[\"model\"], f\"model/{safe_name}.pkl\")\n",
    "\n",
    "print(\"Saved models + scaler into ./model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe35de",
   "metadata": {
    "id": "3efe35de"
   },
   "source": [
    "## 12) Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GCtF4z7_zenA",
   "metadata": {
    "id": "GCtF4z7_zenA"
   },
   "source": [
    "## Comparison Table of Evaluation Metrics\n",
    "\n",
    "| ML Model Name | Accuracy | AUC | Precision | Recall | F1 | MCC |\n",
    "|---------------|----------|------|-----------|--------|------|------|\n",
    "| Logistic Regression | 0.8077 | 0.7076 | 0.6868 | 0.2396 | 0.3553 | 0.3244 |\n",
    "| Decision Tree | 0.7145 | 0.6075 | 0.3694 | 0.4115 | 0.3893 | 0.2042 |\n",
    "| KNN | 0.7928 | 0.7014 | 0.5487 | 0.3564 | 0.4322 | 0.3233 |\n",
    "| Naive Bayes | 0.7525 | 0.7249 | 0.4515 | 0.5539 | 0.4975 | 0.3386 |\n",
    "| Random Forest (Ensemble) | 0.8168 |\t0.7741 |\t0.6597 |\t0.3549 |\t0.4615 |\t0.3883 |\n",
    "| XGBoost (Ensemble) | **0.8167** | **0.7774** | 0.6553 | 0.3610 | 0.4655 | **0.3896** |\n",
    "\n",
    "---\n",
    "\n",
    "## Observations on Model Performance\n",
    "\n",
    "| ML Model Name | Observation about Model Performance |\n",
    "|---------------|-------------------------------------|\n",
    "| Logistic Regression | Achieved good overall accuracy and high precision but very low recall, indicating conservative prediction of default cases. It tends to miss many actual defaulters. |\n",
    "| Decision Tree | Showed the weakest overall performance across most metrics, likely due to overfitting and limited generalization capability. |\n",
    "| KNN | Delivered moderate performance with balanced precision and recall but lower discrimination ability compared to ensemble models. |\n",
    "| Naive Bayes | Achieved the highest recall among all models, indicating better sensitivity in detecting defaulters, though with reduced precision. |\n",
    "| Random Forest (Ensemble) | Demonstrated strong performance with high AUC and MCC, indicating improved stability and generalization compared to individual models. |\n",
    "| XGBoost (Ensemble) | Achieved the best overall performance with highest AUC and MCC. It provides superior class separation and balanced predictive capability. |\n",
    "\n",
    "---\n",
    "\n",
    "## Final Model Selection\n",
    "\n",
    "Based on the comparison of evaluation metrics, **XGBoost** is selected as the best-performing model due to its superior AUC and MCC scores, indicating better overall classification quality and balanced performance on imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f72a7-2e65-4e70-9ef6-1d2e793545ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
